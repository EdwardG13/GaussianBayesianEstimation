"""
Compare minimum MSL vs prior variance for Bayes-optimal S (Lyapunov) 
and linear, quadratic, and cubic ansätze for estimating temperature T 
of a thermal state. The state can be squeezed with parameters r and phi.
"""

import numpy as np
import scipy.linalg as la
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec

# ---------------- User parameters ----------------
N = 30            # Fock truncation
T_min, T_max = 0.01, 5.0  # Temperature range (T > 0)
T_pts = 200       # number of grid points for T

# State parameters
r_squeeze = 0.5   # squeezing parameter
phi_squeeze = 0.0 # squeezing phase

# Prior settings
prior_type = 'log_normal'  # Options: 'gaussian', 'log_normal', 'beta', 'gamma'
T0 = 0.1          # prior mean/center for T
T_sigma = 0.5     # prior width parameter

# Range of prior variances to test
prior_variance_list = np.logspace(-2, 0.5, 10)
# -------------------------------------------------

# Ladder operators in truncated Fock basis
a = np.zeros((N, N), dtype=complex)
for n in range(1, N):
    a[n-1, n] = np.sqrt(n)
adag = a.conj().T
I = np.eye(N, dtype=complex)

# Quadratures
x = (a + adag) / np.sqrt(2)
p = (a - adag) / (1j * np.sqrt(2))

def squeeze_op(r, phi):
    """Squeezing operator S(r,phi) = exp[r/2 * (e^{-2i*phi} a^†^2 - e^{2i*phi} a^2)]"""
    G = 0.5 * (np.exp(-2j*phi) * adag @ adag - np.exp(2j*phi) * a @ a)
    return la.expm(r * G)

def thermal_state(T, r=0.0, phi=0.0):
    """
    Create a thermal state at temperature T, optionally squeezed.
    """
    if T <= 0:
        raise ValueError("Temperature must be positive")
    
    # Thermal state in Fock basis (diagonal)
    n_bar = T  # mean photon number = T (setting hbar*omega/k_B = 1)
    rho_th = np.zeros((N, N), dtype=complex)
    for n in range(N):
        rho_th[n, n] = (n_bar**n) / ((1 + n_bar)**(n+1))
    
    # Apply squeezing if r > 0
    if r > 0:
        S = squeeze_op(r, phi)
        rho_th = S @ rho_th @ S.conj().T
    
    # Ensure hermiticity and normalization
    rho_th = 0.5 * (rho_th + rho_th.conj().T)
    rho_th = rho_th / np.trace(rho_th)
    
    return rho_th

def get_prior(T_grid, prior_type, T0, T_sigma, T_min, T_max):
    """Generate different types of priors on the temperature grid."""
    if prior_type == 'gaussian':
        prior_unnorm = np.exp(-0.5 * ((T_grid - T0) / T_sigma)**2)

    elif prior_type == 'log_normal':
        prior_unnorm = np.exp(-0.5 * ((np.log(T_grid) - T0) / T_sigma)**2)
        
    elif prior_type == 'beta':
        x_scaled = (T_grid - T_min) / (T_max - T_min)
        mu_scaled = (T0 - T_min) / (T_max - T_min)
        mu_scaled = np.clip(mu_scaled, 0.01, 0.99)
        var_scaled = (T_sigma / (T_max - T_min))**2
        var_scaled = np.clip(var_scaled, 1e-6, mu_scaled * (1 - mu_scaled) * 0.99)
        common = mu_scaled * (1 - mu_scaled) / var_scaled - 1
        alpha = max(0.5, mu_scaled * common)
        beta = max(0.5, (1 - mu_scaled) * common)
        with np.errstate(divide='ignore', invalid='ignore'):
            log_prior = (alpha - 1) * np.log(x_scaled + 1e-100) + (beta - 1) * np.log(1 - x_scaled + 1e-100)
            prior_unnorm = np.exp(log_prior)
            prior_unnorm[x_scaled <= 0] = 0
            prior_unnorm[x_scaled >= 1] = 0
            prior_unnorm = np.nan_to_num(prior_unnorm, nan=0.0, posinf=0.0, neginf=0.0)
        
    elif prior_type == 'gamma':
        k = (T0 / T_sigma)**2
        theta = T_sigma**2 / T0
        k = max(0.5, k)
        theta = max(1e-6, theta)
        with np.errstate(over='ignore', under='ignore', invalid='ignore'):
            log_prior = (k - 1) * np.log(T_grid + 1e-100) - T_grid / theta
            prior_unnorm = np.exp(log_prior)
            prior_unnorm = np.nan_to_num(prior_unnorm, nan=0.0, posinf=0.0, neginf=0.0)
    else:
        raise ValueError(f"Unknown prior type: {prior_type}")
    
    # Normalize
    dT = T_grid[1] - T_grid[0]
    total = np.sum(prior_unnorm) * dT
    if total > 1e-100:
        prior = prior_unnorm / total
    else:
        print(f"Warning: Prior normalization failed for {prior_type}, using uniform")
        prior = np.ones_like(T_grid) / ((T_max - T_min))
    
    return prior

def get_optimal_coefficients(barrho, W, B):
    """Compute optimal coefficients alpha^opt for the ansatz."""
    def HS(A, Bop):
        return np.real(np.trace(A.conj().T @ Bop))
    
    m = len(B)
    G = np.zeros((m, m), dtype=float)
    b = np.zeros(m, dtype=float)
    
    for i in range(m):
        for j in range(m):
            G[i, j] = 0.5 * HS(B[i], barrho @ B[j] + B[j] @ barrho)
        b[i] = HS(B[i], W)
    
    # Solve G * alpha = b
    alpha_opt, *_ = la.lstsq(G, b)
    
    return alpha_opt, G, b

def compute_msl_all(T_sigma, T0=1.0, r=0.0, phi=0.0, prior_type='gaussian'):
    """
    Compute MSL for Bayes-optimal and all three ansätze.
    
    Returns:
    - msl_bayes, msl_linear, msl_quad, msl_cubic
    - alpha_linear, alpha_quad, alpha_cubic
    """
    
    T_grid = np.linspace(T_min, T_max, T_pts)
    dT = T_grid[1] - T_grid[0]
    
    # Get prior
    prior = get_prior(T_grid, prior_type, T0, T_sigma, T_min, T_max)
    
    # Build rho(T) list
    rho_list = [thermal_state(T, r, phi) for T in T_grid]
    
    # Compute bar-rho (rho_0) and W (rho_1)
    barrho = sum(prior[i] * rho_list[i] * dT for i in range(len(T_grid)))
    W = sum(prior[i] * np.log(T_grid[i]) * rho_list[i] * dT for i in range(len(T_grid)))
    barrho = 0.5 * (barrho + barrho.conj().T)
    W = 0.5 * (W + W.conj().T)
    
    # Compute lambda (second moment of prior * f(T))
    lambda_val = np.sum(prior * np.log(T_grid)**2 * dT)
    
    # ---------------- Exact Bayes S (Fock basis) ---------------
    dim = N * N
    A_big = np.kron(np.eye(N), barrho) + np.kron(barrho.conj().T, np.eye(N))
    vecW = W.reshape(dim, order='F')
    vecS_bayes = la.pinv(A_big) @ (2.0 * vecW)
    S_bayes = vecS_bayes.reshape((N, N), order='F')
    S_bayes = 0.5 * (S_bayes + S_bayes.conj().T)
    msl_bayes = lambda_val - np.real(np.trace(barrho @ (S_bayes @ S_bayes)))
    
    # ---------------- Linear ansatz: I, x, p -----------------------
    B_linear = [I, x, p]
    B_linear = [0.5 * (M + M.conj().T) for M in B_linear]
    alpha_linear, G_linear, b_linear = get_optimal_coefficients(barrho, W, B_linear)
    msl_linear = lambda_val - b_linear @ la.pinv(G_linear) @ b_linear
    
    # ---------------- Quadratic ansatz: I, x, p, x², (xp+px)/2, p² ---
    B_quad = [I, x, p, x @ x, 0.5 * (x @ p + p @ x), p @ p]
    B_quad = [0.5 * (M + M.conj().T) for M in B_quad]
    alpha_quad, G_quad, b_quad = get_optimal_coefficients(barrho, W, B_quad)
    msl_quad = lambda_val - b_quad @ la.pinv(G_quad) @ b_quad
    
    # ---------------- Cubic ansatz: quadratic + x³, x²p, xp², p³ ---
    x2 = x @ x
    p2 = p @ p
    xp = 0.5 * (x @ p + p @ x)
    x3 = x @ x @ x
    x2p = 0.5 * (x2 @ p + p @ x2)
    xp2 = 0.5 * (x @ p2 + p2 @ x)
    p3 = p @ p @ p
    
    B_cubic = [I, x, p, x2, xp, p2, x3, x2p, xp2, p3]
    B_cubic = [0.5 * (M + M.conj().T) for M in B_cubic]
    alpha_cubic, G_cubic, b_cubic = get_optimal_coefficients(barrho, W, B_cubic)
    msl_cubic = lambda_val - b_cubic @ la.pinv(G_cubic) @ b_cubic
    
    return (msl_bayes, msl_linear, msl_quad, msl_cubic, 
            alpha_linear, alpha_quad, alpha_cubic)

# Compute MSL for each prior variance
msl_bayes_arr = []
msl_linear_arr = []
msl_quad_arr = []
msl_cubic_arr = []
alpha_opt_linear_list = []
alpha_opt_quad_list = []
alpha_opt_cubic_list = []

print("="*70)
print(f"Estimating Temperature T of thermal state")
print(f"State parameters: r = {r_squeeze}, φ = {phi_squeeze}")
print(f"Prior type: {prior_type}")
print(f"Prior center: T₀ = {T0}")
print("="*70)

for i, sigma2 in enumerate(prior_variance_list):
    T_sigma = np.sqrt(sigma2)
    print(f"Progress: {i+1}/{len(prior_variance_list)}, σ² = {sigma2:.4f}", end='')
    
    results = compute_msl_all(
        T_sigma, T0=T0, r=r_squeeze, phi=phi_squeeze, prior_type=prior_type
    )
    
    msl_b, msl_l, msl_q, msl_c, alpha_l, alpha_q, alpha_c = results
    
    msl_bayes_arr.append(msl_b)
    msl_linear_arr.append(msl_l)
    msl_quad_arr.append(msl_q)
    msl_cubic_arr.append(msl_c)
    alpha_opt_linear_list.append(alpha_l)
    alpha_opt_quad_list.append(alpha_q)
    alpha_opt_cubic_list.append(alpha_c)
    
    print(f" -> Bayes={msl_b:.4e}, Linear={msl_l:.4e}, Quad={msl_q:.4e}, Cubic={msl_c:.4e}")

# Convert to arrays
msl_bayes_arr = np.array(msl_bayes_arr)
msl_linear_arr = np.array(msl_linear_arr)
msl_quad_arr = np.array(msl_quad_arr)
msl_cubic_arr = np.array(msl_cubic_arr)

# Plotting
fig = plt.figure(figsize=(14, 10))
gs = GridSpec(2, 2, figure=fig, hspace=0.3, wspace=0.3)

# Plot 1: MSL vs prior variance
ax1 = fig.add_subplot(gs[0, 0])
ax1.loglog(prior_variance_list, msl_bayes_arr, 'o-', linewidth=2.5, 
           markersize=8, label='Bayes-optimal', color='C0')
ax1.loglog(prior_variance_list, msl_linear_arr, 'd--', linewidth=2, 
           markersize=7, label='Linear SPM', color='C3')
ax1.loglog(prior_variance_list, msl_quad_arr, 's--', linewidth=2, 
           markersize=7, label='Quadratic SPM', color='C1')
ax1.loglog(prior_variance_list, msl_cubic_arr, '^:', linewidth=2, 
           markersize=7, label='Cubic SPM', color='C2')
ax1.set_xlabel('Prior variance σ²', fontsize=11)
ax1.set_ylabel('Minimum MSL (MSE)', fontsize=11)
ax1.legend(fontsize=9)

# Plot 2: Ratio to Bayes-optimal
ax2 = fig.add_subplot(gs[0, 1])
ratio_linear = msl_linear_arr / msl_bayes_arr
ratio_quad = msl_quad_arr / msl_bayes_arr
ratio_cubic = msl_cubic_arr / msl_bayes_arr

ax2.axhline(y=1, color='C0', linestyle='-', linewidth=2, alpha=0.5, label='Bayes (ratio=1)')
ax2.semilogx(prior_variance_list, ratio_linear, 'd--', linewidth=2, 
             markersize=7, label='Linear / Bayes', color='C3')
ax2.semilogx(prior_variance_list, ratio_quad, 's--', linewidth=2, 
             markersize=7, label='Quadratic / Bayes', color='C1')
ax2.semilogx(prior_variance_list, ratio_cubic, '^:', linewidth=2, 
             markersize=7, label='Cubic / Bayes', color='C2')
ax2.set_xlabel('Prior variance σ²', fontsize=11)
ax2.set_ylabel('MSL Ratio', fontsize=11)
ax2.legend(fontsize=9)
ax2.grid(False)

# Plot 3: Linear coefficients vs prior variance
ax3 = fig.add_subplot(gs[1, 0])
linear_labels = ['I', 'x', 'p']
alpha_linear_array = np.array(alpha_opt_linear_list)
for i in range(alpha_linear_array.shape[1]):
    ax3.semilogx(prior_variance_list, alpha_linear_array[:, i], 'o-', 
                 linewidth=2, markersize=5, label=linear_labels[i])
ax3.set_xlabel('Prior variance σ²', fontsize=11)
ax3.set_ylabel('Optimal coefficient α', fontsize=11)
ax3.legend(fontsize=9)
ax3.grid(False)

# Plot 4: Quadratic coefficients vs prior variance
ax4 = fig.add_subplot(gs[1, 1])
quad_labels = ['I', 'x', 'p', 'x²', '(xp+px)/2', 'p²']
alpha_quad_array = np.array(alpha_opt_quad_list)
for i in range(alpha_quad_array.shape[1]):
    ax4.semilogx(prior_variance_list, alpha_quad_array[:, i], 'o-', 
                 linewidth=2, markersize=5, label=quad_labels[i])
ax4.set_xlabel('Prior variance σ²', fontsize=11)
ax4.set_ylabel('Optimal coefficient α', fontsize=11)
ax4.legend(fontsize=9, ncol=2)
ax4.grid(False)

plt.tight_layout()
plt.show()

# Print summary
print("\n" + "="*70)
print("Summary:")
print("="*70)
print(f"Prior type: {prior_type}")
print(f"Prior center: T₀ = {T0}")
print(f"State squeezing: r = {r_squeeze}, φ = {phi_squeeze}")
print(f"Prior variance range: σ² ∈ [{prior_variance_list[0]:.3f}, {prior_variance_list[-1]:.3f}]")
print(f"\nFinal MSL values (at σ² = {prior_variance_list[-1]:.3f}):")
print(f"  Bayes-optimal: {msl_bayes_arr[-1]:.6e}")
print(f"  Linear SPM:    {msl_linear_arr[-1]:.6e}")
print(f"  Quadratic SPM: {msl_quad_arr[-1]:.6e}")
print(f"  Cubic SPM:     {msl_cubic_arr[-1]:.6e}")
print(f"\nRatios to Bayes-optimal:")
print(f"  Linear / Bayes:    {ratio_linear[-1]:.4f}")
print(f"  Quadratic / Bayes: {ratio_quad[-1]:.4f}")
print(f"  Cubic / Bayes:     {ratio_cubic[-1]:.4f}")

print(f"\nFinal optimal coefficients α:")
basis_labels_quad = ['I', 'x', 'p', 'x²', '(xp+px)/2', 'p²']
for i, label in enumerate(basis_labels_quad):
    print(f"  α[{label}] = {alpha_opt_quad_list[-1][i]:+.6f}")

### Second probe state ###
# Compute MSL for each prior variance
# msl_bayes_arr2 = []
# msl_linear_arr2 = []
# msl_quad_arr2 = []
# msl_cubic_arr2 = []
# alpha_opt_linear_list2 = []
# alpha_opt_quad_list2 = []
# alpha_opt_cubic_list2 = []