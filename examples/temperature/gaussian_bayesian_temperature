"""
Compare minimum MSL vs prior width for Bayes-optimal S (Lyapunov) 
and quadratic ansatz S for estimating temperature T of a thermal state.
The state can be squeezed with parameters r and phi.
"""

import numpy as np
import scipy.linalg as la
import matplotlib.pyplot as plt
from scipy.special import gamma as gamma_func

# ---------------- User parameters ----------------
N = 20            # Fock truncation
T_min, T_max = 0.01, 5.0  # Temperature range (T > 0)
T_pts = 200       # number of grid points for T

# State parameters
r_squeeze = 0.5   # squeezing parameter
phi_squeeze = 0.0 # squeezing phase

# Prior settings
prior_type = 'gaussian'  # Options: 'gaussian', 'jeffreys', 'beta', 'gamma'
T0 = 1.0          # prior mean/center for T
T_sigma = 0.5     # prior width parameter

# Range of prior widths to test
T_sigma_values = np.logspace(-2, 0.1, 10)  # from 0.01 to ~3.16
# -------------------------------------------------

# Ladder operators in truncated Fock basis
a = np.zeros((N, N), dtype=complex)
for n in range(1, N):
    a[n-1, n] = np.sqrt(n)
adag = a.conj().T
I = np.eye(N, dtype=complex)

# Quadratures
x = (a + adag) / np.sqrt(2)
p = (a - adag) / (1j * np.sqrt(2))

def squeeze_op(r, phi):
    """Squeezing operator S(r,phi) = exp[r/2 * (e^{-2i*phi} a^†^2 - e^{2i*phi} a^2)]"""
    G = 0.5 * (np.exp(-2j*phi) * adag @ adag - np.exp(2j*phi) * a @ a)
    return la.expm(r * G)

def thermal_state(T, r=0.0, phi=0.0):
    """
    Create a thermal state at temperature T, optionally squeezed.
    For thermal state: rho_th = sum_n p_n |n><n| where p_n = (1-e^{-1/T})e^{-n/T}
    If squeezed: rho = S * rho_th * S^†
    """
    if T <= 0:
        raise ValueError("Temperature must be positive")
    
    # Thermal state in Fock basis (diagonal)
    n_bar = T  # mean photon number = T (setting hbar*omega/k_B = 1)
    rho_th = np.zeros((N, N), dtype=complex)
    for n in range(N):
        rho_th[n, n] = (n_bar**n) / ((1 + n_bar)**(n+1))
    
    # Apply squeezing if r > 0
    if r > 0:
        S = squeeze_op(r, phi)
        rho_th = S @ rho_th @ S.conj().T
    
    # Ensure hermiticity and normalization
    rho_th = 0.5 * (rho_th + rho_th.conj().T)
    rho_th = rho_th / np.trace(rho_th)
    
    return rho_th

def get_prior(T_grid, prior_type, T0, T_sigma, T_min, T_max):
    """
    Generate different types of priors on the temperature grid.
    
    Parameters:
    - T_grid: grid of temperature values
    - prior_type: 'gaussian', 'jeffreys', 'beta', 'gamma'
    - T0: center/mean parameter
    - T_sigma: width parameter (interpretation depends on prior_type)
    - T_min, T_max: range of T
    
    For Jeffreys prior: T_sigma controls concentration around T0 via window [T0/exp(T_sigma), T0*exp(T_sigma)]
    """
    if prior_type == 'gaussian':
        # Truncated Gaussian
        prior_unnorm = np.exp(-0.5 * ((T_grid - T0) / T_sigma)**2)
        
    elif prior_type == 'jeffreys':
        # Jeffreys prior: p(T) ∝ 1/T, with concentration controlled by T_sigma
        # We use a windowed version: uniform in log-space around log(T0)
        # Window width in log-space is T_sigma
        log_T = np.log(T_grid + 1e-10)
        log_T0 = np.log(T0)
        # Soft window using Gaussian in log-space
        prior_unnorm = (1.0 / (T_grid + 1e-10)) * np.exp(-0.5 * ((log_T - log_T0) / T_sigma)**2)
        
    elif prior_type == 'beta':
        # Beta distribution rescaled to [T_min, T_max]
        # Use method of moments to set alpha, beta from T0 and T_sigma
        x_scaled = (T_grid - T_min) / (T_max - T_min)
        mu_scaled = (T0 - T_min) / (T_max - T_min)
        
        # Ensure mu_scaled is in (0,1)
        mu_scaled = np.clip(mu_scaled, 0.01, 0.99)
        
        # Variance in scaled coordinates
        var_scaled = (T_sigma / (T_max - T_min))**2
        var_scaled = np.clip(var_scaled, 1e-6, mu_scaled * (1 - mu_scaled) * 0.99)
        
        # Method of moments for beta parameters
        common = mu_scaled * (1 - mu_scaled) / var_scaled - 1
        alpha = mu_scaled * common
        beta = (1 - mu_scaled) * common
        
        # Ensure positive parameters
        alpha = max(0.5, alpha)
        beta = max(0.5, beta)
        
        # Compute in log space to avoid overflow
        with np.errstate(divide='ignore', invalid='ignore'):
            log_prior = (alpha - 1) * np.log(x_scaled + 1e-100) + (beta - 1) * np.log(1 - x_scaled + 1e-100)
            prior_unnorm = np.exp(log_prior)
            prior_unnorm[x_scaled <= 0] = 0
            prior_unnorm[x_scaled >= 1] = 0
            prior_unnorm = np.nan_to_num(prior_unnorm, nan=0.0, posinf=0.0, neginf=0.0)
        
    elif prior_type == 'gamma':
        # Gamma distribution: p(T) ∝ T^(k-1) exp(-T/theta)
        # k (shape) and theta (scale) from mean and variance
        # mean = k*theta = T0, variance = k*theta^2 = T_sigma^2
        k = (T0 / T_sigma)**2
        theta = T_sigma**2 / T0
        
        # Ensure k > 0
        k = max(0.5, k)
        theta = max(1e-6, theta)
        
        # Compute in log space to avoid overflow
        with np.errstate(over='ignore', under='ignore', invalid='ignore'):
            log_prior = (k - 1) * np.log(T_grid + 1e-100) - T_grid / theta
            prior_unnorm = np.exp(log_prior)
            prior_unnorm = np.nan_to_num(prior_unnorm, nan=0.0, posinf=0.0, neginf=0.0)
        
    else:
        raise ValueError(f"Unknown prior type: {prior_type}")
    
    # Normalize
    dT = T_grid[1] - T_grid[0]
    total = np.sum(prior_unnorm) * dT
    if total > 1e-100:
        prior = prior_unnorm / total
    else:
        # Fallback to uniform if normalization fails
        print(f"Warning: Prior normalization failed for {prior_type}, using uniform")
        prior = np.ones_like(T_grid) / ((T_max - T_min))
    
    return prior

def get_optimal_coefficients(barrho, W, B):
    """
    Compute optimal coefficients alpha^opt for the quadratic ansatz.
    
    Parameters:
    - barrho: rho_0 (zeroth moment)
    - W: rho_1 (first moment)
    - B: list of basis operators
    
    Returns:
    - alpha_opt: optimal coefficients
    - G: Gram matrix
    - b: right-hand side vector
    """
    def HS(A, Bop):
        return np.real(np.trace(A.conj().T @ Bop))
    
    m = len(B)
    G = np.zeros((m, m), dtype=float)
    b = np.zeros(m, dtype=float)
    
    for i in range(m):
        for j in range(m):
            G[i, j] = 0.5 * HS(B[i], barrho @ B[j] + B[j] @ barrho)
        b[i] = HS(B[i], W)
    
    # Solve G * alpha = b
    alpha_opt, *_ = la.lstsq(G, b)
    
    return alpha_opt, G, b

def compute_msl_for_prior_width(T_sigma, T0=1.0, r=0.0, phi=0.0, prior_type='gaussian'):
    """
    Compute MSL for both methods given a prior width.
    
    Parameters:
    - T_sigma: prior width parameter
    - T0: prior center/mean
    - r: squeezing parameter
    - phi: squeezing phase
    - prior_type: type of prior distribution
    
    Returns:
    - msl_bayes: MSL for Bayes-optimal S
    - msl_quad: MSL for quadratic ansatz
    - alpha_opt: optimal coefficients for quadratic ansatz
    """
    
    T_grid = np.linspace(T_min, T_max, T_pts)
    dT = T_grid[1] - T_grid[0]
    
    # Get prior
    prior = get_prior(T_grid, prior_type, T0, T_sigma, T_min, T_max)
    
    # Build rho(T) list
    rho_list = []
    for T in T_grid:
        rho = thermal_state(T, r, phi)
        rho_list.append(rho)
    
    # Compute bar-rho (rho_0) and W (rho_1)
    barrho = np.zeros((N, N), dtype=complex)
    W = np.zeros((N, N), dtype=complex)
    for i, T in enumerate(T_grid):
        barrho += prior[i] * rho_list[i] * dT
        W += prior[i] * np.log(T) * rho_list[i] * dT
    barrho = 0.5 * (barrho + barrho.conj().T)
    W = 0.5 * (W + W.conj().T)
    
    # Compute lambda (second moment of prior * f(T))
    lambda_val = np.sum(prior * T_grid**2 * dT)
    
    # ---------------- Exact Bayes S (Fock basis) ---------------
    dim = N * N
    A_big = np.kron(np.eye(N), barrho) + np.kron(barrho.conj().T, np.eye(N))
    vecW = W.reshape(dim, order='F')
    vecS_bayes = la.pinv(A_big) @ (2.0 * vecW)
    S_bayes = vecS_bayes.reshape((N, N), order='F')
    S_bayes = 0.5 * (S_bayes + S_bayes.conj().T)
    
    # MSL for Bayes: L_min = lambda - Tr(rho_0 S^2)
    msl_bayes = lambda_val - np.real(np.trace(barrho @ (S_bayes @ S_bayes)))
    
    # ---------------- Quadratic ansatz -----------------------
    B = []
    B.append(I)
    B.append(x)
    B.append(p)
    B.append(x @ x)
    B.append(0.5 * (x @ p + p @ x))
    B.append(p @ p)
    B = [0.5 * (M + M.conj().T) for M in B]
    
    # Get optimal coefficients
    alpha_opt, G_mat, b_vec = get_optimal_coefficients(barrho, W, B)
    
    # Construct S_quad
    S_quad = sum(alpha_opt[k] * B[k] for k in range(len(B)))
    S_quad = 0.5 * (S_quad + S_quad.conj().T)
    
    # MSL for quadratic: L = lambda - b^T G^{-1} b
    msl_quad = lambda_val - b_vec @ la.pinv(G_mat) @ b_vec
    
    return msl_bayes, msl_quad, alpha_opt

# Compute MSL for each prior width
msl_bayes_list = []
msl_quad_list = []
alpha_opt_list = []

print("="*70)
print(f"Estimating Temperature T of thermal state")
print(f"State parameters: r = {r_squeeze}, φ = {phi_squeeze}")
print(f"Prior type: {prior_type}")
print(f"Prior center: T₀ = {T0}")
print("="*70)

for i, T_sigma in enumerate(T_sigma_values):
    print(f"Progress: {i+1}/{len(T_sigma_values)}, σ = {T_sigma:.4f}", end='')
    msl_b, msl_q, alpha = compute_msl_for_prior_width(
        T_sigma, T0=T0, r=r_squeeze, phi=phi_squeeze, prior_type=prior_type
    )
    msl_bayes_list.append(msl_b)
    msl_quad_list.append(msl_q)
    alpha_opt_list.append(alpha)
    print(f" -> MSL_Bayes={msl_b:.4e}, MSL_Quad={msl_q:.4e}")

# Plotting
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: MSL vs prior width
ax1.loglog(T_sigma_values, msl_bayes_list, 'o-', linewidth=2, 
           markersize=7, label='Full Bayes-optimal S (Lyapunov)')
ax1.loglog(T_sigma_values, msl_quad_list, 's--', linewidth=2, 
           markersize=7, label='Constrained S (Quadratic ansatz)')
ax1.set_xlabel('Prior width σ', fontsize=12)
ax1.set_ylabel('Minimum MSL', fontsize=12)
ax1.set_title(f'MSL vs Prior Width (T₀={T0}, r={r_squeeze}, φ={phi_squeeze})', fontsize=12)
ax1.legend(fontsize=10)
ax1.grid(True, which='both', alpha=0.3)

# # Plot 2: Optimal coefficients vs prior width
# basis_labels = ['I', 'x', 'p', 'x²', '(xp+px)/2', 'p²']
# alpha_array = np.array(alpha_opt_list)
# for i in range(alpha_array.shape[1]):
#     ax2.semilogx(T_sigma_values, alpha_array[:, i], 'o-', 
#                  linewidth=2, markersize=5, label=basis_labels[i])
# ax2.set_xlabel('Prior width σ', fontsize=12)
# ax2.set_ylabel('Optimal coefficient α', fontsize=12)
# ax2.set_title('Quadratic Ansatz Coefficients vs Prior Width', fontsize=12)
# ax2.legend(fontsize=10, ncol=2)
# ax2.grid(True, which='both', alpha=0.3)

# Plot 2: Optimal coefficients vs prior width
basis_labels = ['I', 'x', 'p', 'x²', '(xp+px)/2', 'p²']
alpha_array = np.array(alpha_opt_list)
for i in [0,3,4,5]:
    ax2.semilogx(T_sigma_values, alpha_array[:, i], 'o-', 
                 linewidth=2, markersize=5, label=basis_labels[i])
ax2.set_xlabel('Prior width σ', fontsize=12)
ax2.set_ylabel('Optimal coefficient α', fontsize=12)
ax2.set_title('Quadratic Ansatz Coefficients vs Prior Width', fontsize=12)
ax2.legend(fontsize=10, ncol=2)
ax2.grid(True, which='both', alpha=0.3)

plt.tight_layout()
plt.show()

# Print summary
print("\n" + "="*70)
print("Summary:")
print("="*70)
print(f"Prior type: {prior_type}")
print(f"Prior center: T₀ = {T0}")
print(f"State squeezing: r = {r_squeeze}, φ = {phi_squeeze}")
print(f"Prior width range: σ ∈ [{T_sigma_values[0]:.3f}, {T_sigma_values[-1]:.3f}]")
print(f"\nFinal MSL values (at σ = {T_sigma_values[-1]:.3f}):")
print(f"  Bayes-optimal: {msl_bayes_list[-1]:.6e}")
print(f"  Quadratic:     {msl_quad_list[-1]:.6e}")
print(f"  Ratio (Quad/Bayes): {msl_quad_list[-1]/msl_bayes_list[-1]:.4f}")
print(f"\nFinal optimal coefficients α:")
for i, label in enumerate(basis_labels):
    print(f"  α[{label}] = {alpha_opt_list[-1][i]:+.6f}")